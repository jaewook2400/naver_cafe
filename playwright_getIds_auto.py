import os
import time
from playwright.sync_api import sync_playwright
from playwright_stealth import Stealth
import random
import re
import csv


def random_sleep(min_seconds, max_seconds):
    sleep_time = random.uniform(min_seconds, max_seconds)
    print(f"{sleep_time:.2f}ì´ˆ ë™ì•ˆ ëŒ€ê¸°")
    time.sleep(sleep_time)


def human_click(page, locator):
    """
    íƒì§€ì— ê±¸ë¦¬ì§€ ì•Šê¸° ìœ„í•´
    ì‚¬ëŒì²˜ëŸ¼ ë§ˆìš°ìŠ¤ë¥¼ ì´ë™í•˜ì—¬ í´ë¦­í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # í•´ë‹¹ ìš”ì†Œê°€ ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤
        random_sleep(0.3, 0.7)

        box = locator.bounding_box()
        if box:
            target_x = box["x"] + box["width"] * random.uniform(0.2, 0.8)
            target_y = box["y"] + box["height"] * random.uniform(0.2, 0.8)

            page.mouse.move(target_x, target_y, steps=random.randint(20, 60))
            random_sleep(0.1, 0.3)
            page.mouse.down()
            random_sleep(0.05, 0.15)
            page.mouse.up()
        else:
            locator.click()
    except Exception as e:
        print(f"  [Human Click] ì‹¤íŒ¨: {e}")
        locator.click()


TARGET_URL = "https://www.naver.com"
AUTH_FILE = "auth.json"
TARGET_CAFE_MENU_URL = "https://m.cafe.naver.com/ca-fe/web/cafes/21771803?tab=popular"

# í™˜ê²½ë³€ìˆ˜ë¡œ ë²”ìœ„ ì„¤ì • (ê¸°ë³¸ê°’: 0-100)
START_INDEX = int(os.environ.get("START", 0))
END_INDEX = int(os.environ.get("END", 100))
WORKER_ID = os.environ.get("WORKER", "0")

BATCH_SIZE = 100
MIN_BATCH_WAIT = 0
MAX_BATCH_WAIT = 5
# URLì—ì„œ ì¹´í˜ ID ì¶”ì¶œ (cafes/ ë’¤ì˜ ìˆ«ì)
MENU_ID = TARGET_CAFE_MENU_URL.split("cafes/")[1].split("?")[0]
CSV_FILENAME = f"collected_data_menu{MENU_ID}_worker{WORKER_ID}.csv"

print(f"[Worker {WORKER_ID}] ë²”ìœ„: {START_INDEX} ~ {END_INDEX}, ì €ì¥: {CSV_FILENAME}")


def extract_naver_id(html_content):
    """
    HTML ì†ŒìŠ¤ì—ì„œ ë„¤ì´ë²„ ID ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # onload íŒ¨í„´ì—ì„œ JSON í˜•ì‹ ë°ì´í„°ë¡œ ë˜ì–´ìˆëŠ” ë‘ ë²ˆì§¸ ì¸ì ì¶”ì¶œ
        pattern = re.compile(r"onload\('([^']+)',\s*'([^']+)'\);")
        matches = pattern.findall(html_content)

        if matches:
            nickname = matches[0][0]
            print(f"ì¶”ì¶œëœ ë‹‰ë„¤ì„: {nickname}")
            return nickname
    except Exception as e:
        print(f"  [Error] ID ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def extract_level(page):
    try:
        if "íƒˆí‡´" in page.locator(".nickname").inner_text():
            return ""
        grade = page.locator(".member_grade").inner_text()
        # "ë“±ê¸‰\nì„±ì‹¤ë§˜" í˜•ì‹ì—ì„œ ë‘ ë²ˆì§¸ ì¤„ë§Œ ì¶”ì¶œ
        return grade.strip().split("\n")[-1].strip()
    except Exception as e:
        print(f"  ë ˆë²¨ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return ""


def extract_post_info(page):
    """
    ê²Œì‹œê¸€ í˜ì´ì§€ì—ì„œ ì œëª©, ì‘ì„±ì ë‹‰ë„¤ì„, ì‘ì„± ì‹œê°„, ì¡°íšŒìˆ˜ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    ì œëª© ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ë‹¤ìŒ ê²Œì‹œê¸€ë¡œ ë„˜ì–´ê°€ê¸° ìœ„í•¨)
    """
    post_info = {
        "title": "",
        "nickname": "",
        "write_time": "",
        "view_count": "",
    }

    try:
        title_elem = page.locator(".tit").first
        post_info["title"] = title_elem.inner_text().strip() if title_elem else ""
        if not post_info["title"]:
            print("  ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: ì œëª©ì´ ë¹„ì–´ìˆìŒ")
            return None
    except Exception as e:
        print(f"  ì œëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None

    try:
        nick_elem = page.locator(".nick .end_user_nick").first
        post_info["nickname"] = nick_elem.inner_text().strip() if nick_elem else ""
    except Exception as e:
        print(f"  ë‹‰ë„¤ì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    try:
        time_elem = page.locator(".date").first
        post_info["write_time"] = time_elem.inner_text().strip().split("\n")[-1].strip() if time_elem else ""
    except Exception as e:
        print(f"  ì‘ì„± ì‹œê°„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    try:
        view_elem = page.locator(".no").first
        post_info["view_count"] = view_elem.inner_text().strip() if view_elem else ""
    except Exception as e:
        print(f"  ì¡°íšŒìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return post_info


def process_post(page, index, is_first_post=True):
    """
    is_first_post: Trueë©´ ëª©ë¡ì—ì„œ ìŠ¤í¬ë¡¤í•˜ì—¬ ì°¾ê¸°,
                   Falseë©´ siblingContentì—ì„œ ë‹¤ìŒ ê²Œì‹œê¸€ë¡œ ì´ë™
    """
    print(f"\n[{index + 1}ë²ˆì§¸ ê²Œì‹œê¸€ ì²˜ë¦¬ ì¤‘]")

    # 2. ië²ˆì§¸ ê²Œì‹œê¸€ì—ì„œ ì •ë³´ ì¶”ì¶œ
    post_item = None
    post_info = {
        "title": "",
        "nickname": "",
        "write_time": "",
        "view_count": "",
        "naver_id": "",
        "level": "",
    }

    try:
        if is_first_post:
            # ì²«ë²ˆì§¸ ê²Œì‹œë¬¼: ëª©ë¡ì—ì„œ ìŠ¤í¬ë¡¤í•˜ì—¬ ì°¾ê¸°
            # ê²Œì‹œê¸€ ëª©ë¡ ë¡œë”© ëŒ€ê¸°
            try:
                page.wait_for_selector(".PopularArticleList .ListItem", timeout=5000)
            except Exception:
                print("ê²Œì‹œê¸€ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None

            # ë¦¬ìŠ¤íŠ¸ ìš”ì†Œ ë‹¤ì‹œ ì°¾ê¸° (ê´‘ê³  ê²Œì‹œê¸€ ì œì™¸)
            post_selector = ".PopularArticleList .ListItem:not(.adtype_infinity)"

            # í•´ë‹¹ ì¸ë±ìŠ¤ì˜ ê²Œì‹œê¸€ì´ ë¡œë“œë  ë•Œê¹Œì§€ ìŠ¤í¬ë¡¤
            prev_count = 0
            no_change_count = 0
            max_no_change = 20  # 20íšŒ ì—°ì† ë³€í™” ì—†ìœ¼ë©´ ì¢…ë£Œ

            while True:
                current_count = page.locator(post_selector).count()
                print(f"í˜„ì¬ ë¡œë“œëœ ê²Œì‹œê¸€ ìˆ˜: {current_count}, í•„ìš”í•œ ì¸ë±ìŠ¤: {index}")

                if current_count > index:
                    # ì›í•˜ëŠ” ê²Œì‹œê¸€ì´ ë¡œë“œë¨
                    break

                # ê²Œì‹œê¸€ ìˆ˜ ë³€í™” ì²´í¬
                if current_count == prev_count:
                    no_change_count += 1
                    if no_change_count >= max_no_change:
                        print(f"[ERROR] ê²Œì‹œê¸€ ìˆ˜ê°€ {current_count}ê°œì—ì„œ ë” ì´ìƒ ì¦ê°€í•˜ì§€ ì•ŠìŒ. ì¸ë±ìŠ¤ {index}ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        return None
                else:
                    no_change_count = 0
                prev_count = current_count

                # ì•„ì§ ë¡œë“œ ì•ˆë¨ -> í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
                for _ in range(4):  # 3ë²ˆ ìŠ¤í¬ë¡¤
                    page.mouse.wheel(0, 1000)
                    page.wait_for_timeout(200)

                # ìŠ¤í¬ë¡¤ í›„ ì ì‹œ ëŒ€ê¸°
                page.wait_for_timeout(300)

                # "ë”ë³´ê¸°" ë²„íŠ¼ ì°¾ì•„ì„œ í´ë¦­
                more_btn = page.locator(".btn_list_more button.CdsButton").first
                if more_btn.is_visible():
                    print("ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­")
                    human_click(page, more_btn)
                    page.wait_for_timeout(800)
                else:
                    # ë”ë³´ê¸° ë²„íŠ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€ ìŠ¤í¬ë¡¤ ì‹œë„
                    page.mouse.wheel(0, 1000)
                    page.wait_for_timeout(300)

            post_item = page.locator(post_selector).nth(index)
            post_item.scroll_into_view_if_needed()
            random_sleep(0.3, 0.5)

            print("ìŠ¤í¬ë¡¤ ì™„ë£Œ")

            # í´ë¦­ ì „ í˜„ì¬ URL ì €ì¥
            url_before_click = page.url

            target_link = post_item.locator("a").first
            human_click(page, target_link)

            page.wait_for_load_state("domcontentloaded")
            random_sleep(0.5, 1)

            # URL ë³€ê²½ í™•ì¸ ë° ê²Œì‹œê¸€ í˜ì´ì§€ ê²€ì¦
            current_url = page.url
            retry_count = 0
            max_retries = 3

            while current_url == url_before_click or "tab=popular" in current_url:
                retry_count += 1
                if retry_count > max_retries:
                    print(f"  [WARNING] {max_retries}íšŒ ì¬ì‹œë„ í›„ì—ë„ ê²Œì‹œê¸€ ì´ë™ ì‹¤íŒ¨")
                    break

                print(f"  [WARNING] URL ë³€ê²½ ì•ˆë¨, ì¬ì‹œë„ {retry_count}/{max_retries}...")

                # ê²Œì‹œê¸€ ë‹¤ì‹œ ì°¾ì•„ì„œ í´ë¦­
                post_item = page.locator(post_selector).nth(index)
                post_item.scroll_into_view_if_needed()
                random_sleep(0.3, 0.5)

                target_link = post_item.locator("a").first
                try:
                    # expect_navigationìœ¼ë¡œ ëª…ì‹œì  ë„¤ë¹„ê²Œì´ì…˜ ëŒ€ê¸°
                    with page.expect_navigation(timeout=10000):
                        target_link.click()
                except Exception as nav_err:
                    print(f"  [WARNING] ë„¤ë¹„ê²Œì´ì…˜ ëŒ€ê¸° ì‹¤íŒ¨: {nav_err}")

                page.wait_for_load_state("domcontentloaded")
                random_sleep(0.5, 1)
                current_url = page.url

            # ê²Œì‹œê¸€ í˜ì´ì§€ ì œëª© ìš”ì†Œ ë¡œë”© ëŒ€ê¸°
            try:
                page.wait_for_selector(".tit", timeout=5000)
                print("ê²Œì‹œê¸€ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
            except Exception:
                print("  [WARNING] ê²Œì‹œê¸€ ì œëª© ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

            print(f"  [DEBUG] ìµœì¢… URL: {current_url}")
        else:
            # ë‘ë²ˆì§¸ ê²Œì‹œë¬¼ë¶€í„°: siblingContentì—ì„œ ë‹¤ìŒ ê²Œì‹œê¸€ í´ë¦­
            print("siblingContentì—ì„œ ë‹¤ìŒ ê²Œì‹œê¸€ ì°¾ëŠ” ì¤‘...")
            post_selector = ".SiblingArticleFlicker .PREV_NEXT .BasicArticleList"

            basic_list = page.locator(post_selector)

            # .nowì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ ê·¸ ë‹¤ìŒ í•­ëª© ì„ íƒ
            all_items = basic_list.first.locator(".ListItem")
            now_index = -1
            for i in range(all_items.count()):
                if "now" in (all_items.nth(i).get_attribute("class") or ""):
                    now_index = i
                    break

            next_post = None
            if now_index >= 0 and now_index + 1 < all_items.count():
                # next_postì˜ a íƒœê·¸
                next_post = all_items.nth(now_index + 1).locator("a").first

            if next_post and next_post.is_visible():
                url_before_click = page.url

                # í´ë¦­ê³¼ ë™ì‹œì— ë„¤ë¹„ê²Œì´ì…˜ ëŒ€ê¸°
                try:
                    with page.expect_navigation(timeout=10000):
                        next_post.click()
                except Exception as nav_err:
                    print(f"  [WARNING] ë„¤ë¹„ê²Œì´ì…˜ ëŒ€ê¸° ì‹¤íŒ¨: {nav_err}")

                page.wait_for_load_state("domcontentloaded")
                random_sleep(0.5, 1)
                current_url = page.url

                # URL ë³€ê²½ ë° ìœ íš¨ì„± ê²€ì¦
                retry_count = 0
                max_retries = 2

                while current_url == url_before_click or "tab=popular" in current_url:
                    retry_count += 1
                    if retry_count > max_retries:
                        print(f"  [WARNING] ë‹¤ìŒ ê²Œì‹œê¸€ ì´ë™ ì‹¤íŒ¨, ëª©ë¡ì—ì„œ ì¬ì‹œë„")
                        page.goto(TARGET_CAFE_MENU_URL)
                        page.wait_for_load_state("domcontentloaded")
                        random_sleep(1, 2)
                        return process_post(page, index, is_first_post=True)

                    print(f"  [WARNING] URL ë³€ê²½ ì•ˆë¨, ì¬ì‹œë„ {retry_count}/{max_retries}...")
                    next_post.click()
                    page.wait_for_timeout(1500)
                    current_url = page.url

                # ê²Œì‹œê¸€ í˜ì´ì§€ ì œëª© ìš”ì†Œ ë¡œë”© ëŒ€ê¸°
                try:
                    page.wait_for_selector(".tit", timeout=5000)
                    print("ë‹¤ìŒ ê²Œì‹œê¸€ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.")
                except Exception:
                    print("  [WARNING] ê²Œì‹œê¸€ ì œëª© ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")

                print(f"  [DEBUG] ìµœì¢… URL: {current_url}")
            else:
                print("ë‹¤ìŒ ê²Œì‹œê¸€ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ, ëª©ë¡ìœ¼ë¡œ ë³µê·€í•˜ì—¬ ì¬ì‹œë„")
                page.goto(TARGET_CAFE_MENU_URL)
                page.wait_for_load_state("domcontentloaded")
                random_sleep(1, 2)
                # ì¬ê·€ í˜¸ì¶œë¡œ ëª©ë¡ì—ì„œ ì°¾ê¸°
                return process_post(page, index, is_first_post=True)

        # ê²Œì‹œê¸€ URL ì €ì¥ (ë‚˜ì¤‘ì— ë³µê·€ìš©)
        post_url = page.url
        print(f"  ê²Œì‹œê¸€ URL ì €ì¥: {post_url}")

        # URL ìœ íš¨ì„± ê²€ì‚¬ - ëª©ë¡ URLì´ë©´ ìŠ¤í‚µ
        if "tab=popular" in post_url or post_url == TARGET_CAFE_MENU_URL:
            print("  [ERROR] ê²Œì‹œê¸€ í˜ì´ì§€ê°€ ì•„ë‹Œ ëª©ë¡ í˜ì´ì§€ì„ -> ìŠ¤í‚µ")
            return None

        # ê²Œì‹œê¸€ ìƒì„¸ í˜ì´ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ
        extracted_info = extract_post_info(page)
        if extracted_info is None:
            print("  ì œëª© ì¶”ì¶œ ì‹¤íŒ¨ -> ë‹¤ìŒ ê²Œì‹œê¸€ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            return None
        post_info.update(extracted_info)
        print(f"  ì œëª©: {post_info['title']}")
        print(f"  ë‹‰ë„¤ì„: {post_info['nickname']}")
        print(f"  ì‘ì„±ì‹œê°„: {post_info['write_time']}")
        print(f"  ì¡°íšŒìˆ˜: {post_info['view_count']}")

        # ì‚¬ëŒì´ ìŠ¤í¬ë¡¤í•œ ì²™
        page.mouse.wheel(0, random.randint(-20, 20))
        random_sleep(0.2, 0.5)
    except Exception as e:
        print(f"ê²Œì‹œê¸€ í´ë¦­ ì‹¤íŒ¨: {e}")
        return post_info

    # ì‘ì„±ì í”„ë¡œí•„ í´ë¦­
    try:
        profile_link = page.locator(".user_wrap .info").locator("a").first
        human_click(page, profile_link)

        page.wait_for_load_state("domcontentloaded")
        print("ì‘ì„±ì í”„ë¡œí•„ì„ í´ë¦­í–ˆìŠµë‹ˆë‹¤.")
        random_sleep(1, 2)

        # ë“±ê¸‰ ìš”ì†Œ ë¡œë”© ëŒ€ê¸°
        try:
            page.wait_for_selector(".member_grade", timeout=3000)
        except Exception:
            print("  [DEBUG] .member_grade ë¡œë”© ëŒ€ê¸° ì‹¤íŒ¨")

        # ì‘ì„±ì ë ˆë²¨ ì¶”ì¶œ
        level = extract_level(page)
        post_info["level"] = level
        print(f"  ì‘ì„±ì ë ˆë²¨: {level}")
    except Exception as e:
        print(f"í”„ë¡œí•„ í´ë¦­ ì‹¤íŒ¨: {e}")
        return post_info

    # ìª½ì§€ ë³´ë‚´ê¸° ë²„íŠ¼ í´ë¦­ ë° ID ì¶”ì¶œ
    try:
        if "íƒˆí‡´" in page.locator(".nickname").inner_text():
            post_info["naver_id"] = "íƒˆí‡´í•œ ë©¤ë²„"
            # ê·¸ë¦¬ê³  ë„˜ì–´ê°€ê¸° (ID ì¶”ì¶œ ê±´ë„ˆë›°ê³  ë‹¤ìŒë‹¨ê³„)
        else:
            menu_btn = page.locator(".HeaderGnbRight").get_by_role("button").nth(2)
            human_click(page, menu_btn)
            random_sleep(0.3, 0.6)

            message_btn = page.locator(".CdsButtonGroup").locator("button").nth(0)
            human_click(page, message_btn)
            print("ìª½ì§€ ë³´ë‚´ê¸° í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.")

            page.wait_for_load_state("networkidle")
            random_sleep(0.5, 1)
            # HTMLì—ì„œ ID ì¶”ì¶œ
            html_content = page.content()
            real_id = extract_naver_id(html_content)

            if real_id:
                print(f"ì¶”ì¶œ ì„±ê³µ! ID: {real_id}")
                post_info["naver_id"] = real_id
            else:
                print("ID ì¶”ì¶œ ì‹¤íŒ¨")

    except Exception:
        print("ìª½ì§€ ë³´ë‚´ê¸°/ID ì¶”ì¶œ ê³¼ì • ì‹¤íŒ¨")

    # ê²Œì‹œê¸€ í˜ì´ì§€ë¡œ ë³µê·€ (ë‹¤ìŒ ê²Œì‹œê¸€ ì´ë™ì„ ìœ„í•´)
    try:
        print(f"  ê²Œì‹œê¸€ë¡œ ë³µê·€: {post_url}")
        page.goto(post_url)
        page.wait_for_load_state("domcontentloaded")
        random_sleep(0.5, 1)
        print("  ê²Œì‹œê¸€ ë³µê·€ ì™„ë£Œ!")
    except Exception as e:
        print(f"  ê²Œì‹œê¸€ ë³µê·€ ì‹¤íŒ¨: {e}")

    return post_info


def save_batch_to_csv(collected_data, batch_start, batch_end):
    """ë°°ì¹˜ ë°ì´í„°ë¥¼ CSV íŒŒì¼ì— ì €ì¥ (ê°™ì€ ë²ˆí˜¸ëŠ” ë®ì–´ì”Œì›€)"""
    fieldnames = ["ë²ˆí˜¸", "ì œëª©", "ì‘ì„±ì_ë‹‰ë„¤ì„", "ì‘ì„±ì‹œê°„", "ì¡°íšŒìˆ˜", "ë„¤ì´ë²„_ID", "ë“±ê¸‰"]

    # ê¸°ì¡´ ë°ì´í„° ì½ê¸° (ë²ˆí˜¸ë¥¼ í‚¤ë¡œ í•˜ëŠ” dict)
    existing_data = {}
    if os.path.exists(CSV_FILENAME):
        with open(CSV_FILENAME, "r", encoding="utf-8-sig", newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                existing_data[int(row["ë²ˆí˜¸"])] = row

    # ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ (ê°™ì€ ë²ˆí˜¸ë©´ ë®ì–´ì”Œì›€)
    for idx, data in enumerate(collected_data):
        row_num = batch_start + idx
        existing_data[row_num] = {
            "ë²ˆí˜¸": row_num,
            "ì œëª©": data.get("title", ""),
            "ì‘ì„±ì_ë‹‰ë„¤ì„": data.get("nickname", ""),
            "ì‘ì„±ì‹œê°„": data.get("write_time", ""),
            "ì¡°íšŒìˆ˜": data.get("view_count", ""),
            "ë„¤ì´ë²„_ID": data.get("naver_id", ""),
            "ë“±ê¸‰": data.get("level", ""),
        }

    # ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì „ì²´ ë‹¤ì‹œ ì“°ê¸°
    with open(CSV_FILENAME, "w", encoding="utf-8-sig", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row_num in sorted(existing_data.keys()):
            writer.writerow(existing_data[row_num])

    print(f" {CSV_FILENAME} íŒŒì¼ì— {len(collected_data)}ê°œ ì €ì¥ (ë®ì–´ì”Œì›€)ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return CSV_FILENAME


def run_automation():
    # auth.json íŒŒì¼ í™•ì¸
    if not os.path.exists(AUTH_FILE):
        print(f"âŒ '{AUTH_FILE}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. 'make_auth.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
        return

    total_batches = (END_INDEX - START_INDEX + BATCH_SIZE - 1) // BATCH_SIZE

    current_index = START_INDEX
    batch_num = 0

    while current_index < END_INDEX:
        batch_num += 1
        batch_start = current_index
        batch_end = min(current_index + BATCH_SIZE, END_INDEX)

        print(f"\n{'=' * 50}")
        print(f"ğŸ“¦ ë°°ì¹˜ {batch_num}/{total_batches} ì‹œì‘")
        print(f"   ì²˜ë¦¬ ë²”ìœ„: {batch_start} ~ {batch_end - 1}")
        print(f"{'=' * 50}")

        batch_start_time = time.time()
        collected_data = []

        with sync_playwright() as p:
            print("ì €ì¥ëœ ë¡œê·¸ì¸ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")

            iphone = p.devices["iPhone 14 Pro Max"]

            browser = p.chromium.launch(
                headless=True,
                args=[
                    "--disable-blink-features=AutomationControlled",
                    "--disable-infobars",
                ],
            )
            context = browser.new_context(
                **iphone,
                storage_state=AUTH_FILE,
                locale="ko-KR",
                timezone_id="Asia/Seoul",
            )

            page = context.new_page()
            page.route("**/*.{png,jpg,jpeg,gif,webp,svg,woff,woff2}", lambda route: route.abort())
            # playwright-stealth ì ìš© (íƒì§€ íšŒí”¼)
            Stealth().apply_stealth_sync(page)

            # ë„¤ì´ë²„ ì ‘ì†
            page.goto(TARGET_URL)
            page.wait_for_load_state("domcontentloaded")
            print(f"âœ… {TARGET_URL} ì ‘ì† ì„±ê³µ! (ë¡œê·¸ì¸ëœ ìƒíƒœ)")
            time.sleep(2)

            # ì¹´í˜ ì‚¬ì´íŠ¸ ì´ë™
            page.goto(TARGET_CAFE_MENU_URL)
            page.wait_for_load_state("domcontentloaded")
            random_sleep(2, 3)

            # ê²Œì‹œê¸€ ì²˜ë¦¬
            for i in range(batch_start, batch_end):
                try:
                    is_first = i == batch_start  # ë°°ì¹˜ì˜ ì²« ê²Œì‹œê¸€ì¸ì§€
                    post_info = process_post(page, i, is_first_post=is_first)
                    if post_info:
                        collected_data.append(post_info)
                    else:
                        collected_data.append(
                            {
                                "title": "FAILED",
                                "nickname": "",
                                "write_time": "",
                                "view_count": "",
                                "naver_id": "",
                                "level": "",
                            }
                        )
                except Exception:
                    print(f"[{i + 1}ë²ˆì§¸] ì˜¤ë¥˜ ë°œìƒ")
                    collected_data.append(
                        {
                            "title": "ERROR",
                            "nickname": "",
                            "write_time": "",
                            "view_count": "",
                            "naver_id": "",
                            "level": "",
                        }
                    )

                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëª©ë¡ìœ¼ë¡œ ë³µê·€
                    try:
                        page.goto(TARGET_CAFE_MENU_URL)
                        time.sleep(3)
                    except Exception:
                        pass

                print("-" * 30)

                # ê° ê²Œì‹œê¸€ ì²˜ë¦¬ í›„ ëœë¤ ëŒ€ê¸° (ë°°ì¹˜ ë‚´ ë§ˆì§€ë§‰ ê²Œì‹œê¸€ ì œì™¸)
                if i < batch_end - 1:
                    wait_time = random.uniform(1, 3)
                    print(f"â³ ë‹¤ìŒ ê²Œì‹œê¸€ê¹Œì§€ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                    time.sleep(wait_time)

            browser.close()

        # ë°ì´í„° ì €ì¥
        save_batch_to_csv(collected_data, batch_start, batch_end)

        batch_elapsed = time.time() - batch_start_time
        batch_minutes = int(batch_elapsed // 60)
        batch_seconds = batch_elapsed % 60
        avg_per_post = batch_elapsed / len(collected_data) if collected_data else 0

        print(f"\n{'=' * 50}")
        print(f"âœ… ë°°ì¹˜ {batch_num} ì™„ë£Œ! (ìˆ˜ì§‘: {len(collected_data)}ê°œ)")
        print(f"   ì†Œìš” ì‹œê°„: {batch_minutes}ë¶„ {batch_seconds:.1f}ì´ˆ")
        print(f"   ê²Œì‹œê¸€ë‹¹ í‰ê· : {avg_per_post:.1f}ì´ˆ")
        print(f"{'=' * 50}")

        # ë‹¤ìŒ ë°°ì¹˜ë¡œ ì´ë™
        current_index = batch_end

        # ë‹¤ìŒ ë°°ì¹˜ê°€ ìˆìœ¼ë©´ ëŒ€ê¸°
        if current_index < END_INDEX:
            wait_minutes = random.uniform(MIN_BATCH_WAIT, MAX_BATCH_WAIT)
            print(f"\n{'=' * 50}")
            print(f"ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ {wait_minutes:.1f}ë¶„ ëŒ€ê¸°")
            print(f"   ë‹¤ìŒ ë°°ì¹˜: {current_index} ~ {min(current_index + BATCH_SIZE, END_INDEX) - 1}")
            print(f"{'=' * 50}")
            time.sleep(wait_minutes * 60)  # ë¶„ -> ì´ˆ ë³€í™˜

    print(f"\n{'=' * 50}")
    print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print(f"   ì²˜ë¦¬ ë²”ìœ„: {START_INDEX} ~ {END_INDEX - 1}")
    print(f"   ì´ ë°°ì¹˜: {batch_num}ê°œ")
    print(f"{'=' * 50}")


if __name__ == "__main__":
    run_automation()
